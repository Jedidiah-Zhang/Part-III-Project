{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions import *\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = getStaticLinkData()\n",
    "adj_matrix, upstreams = getSpatialData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples1 = getTemporalData(\"../datasets/gy_link_travel_time_part1.txt\")\n",
    "samples2 = getTemporalData(\"../datasets/gy_link_travel_time_part2.txt\")\n",
    "samples3 = getTemporalData(\"../datasets/gy_link_travel_time_part3.txt\")\n",
    "samples = tf.concat([samples1, samples2], 0)\n",
    "samples = tf.concat([samples, samples3], 0)\n",
    "del samples1, samples2, samples3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_1 = datetime(2016, 3, 1)\n",
    "end_date_1 = datetime(2016, 6, 1)\n",
    "start_date_2 = datetime(2017, 3, 1)\n",
    "end_date_2 = datetime(2017, 7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedData1 = sortLinks(samples, start_date_1, end_date_1)\n",
    "sortedData2 = sortLinks(samples, start_date_2, end_date_2)\n",
    "del samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localised Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_data1 = tf.concat([tf.broadcast_to(stat_data, [sortedData1.shape[0], sortedData1.shape[1], stat_data.shape[-1]]), sortedData1], 2)\n",
    "# temp_data2 = tf.concat([tf.broadcast_to(stat_data, [sortedData2.shape[0], sortedData2.shape[1], stat_data.shape[-1]]), sortedData2], 2)\n",
    "temp_data1 = sortedData1\n",
    "temp_data2 = sortedData2\n",
    "temp_data1.shape, temp_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = callbacks.LearningRateScheduler(scheduler)\n",
    "earlystop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pure Temporal Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 22\n",
    "train1, test1 = createSeq(temp_data1[:, id, :], INPUT_LENGTH, PREDICT_LENGTH, TEST_LEN)\n",
    "train2, test2 = createSeq(temp_data2[:, id, :], INPUT_LENGTH, PREDICT_LENGTH, TEST_LEN)\n",
    "\n",
    "X_train = tf.concat([train1[0], train2[0]], 0)\n",
    "y_train = tf.concat([train1[1], train2[1]], 0)\n",
    "X_test = tf.concat([test1[0], test2[0]], 0)\n",
    "y_test = tf.concat([test1[1], test2[1]], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rate of missing values in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.cast(tf.equal(y_test, 0), dtype=tf.int32)).numpy() / (y_test.shape[0] * y_test.shape[1]), \\\n",
    "tf.reduce_sum(tf.cast(tf.equal(y_train, 0), dtype=tf.int32)).numpy() / (y_train.shape[0] * y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../datasets/temporal_x_train.npy', X_train)\n",
    "np.save('../datasets/temporal_y_train.npy', y_train)\n",
    "np.save('../datasets/temporal_x_test.npy', X_test)\n",
    "np.save('../datasets/temporal_y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, X_test= normalize(X_train, test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../datasets/temporal_x_train.npy')\n",
    "y_train = np.load('../datasets/temporal_y_train.npy')\n",
    "X_test = np.load('../datasets/temporal_x_test.npy')\n",
    "y_test = np.load('../datasets/temporal_y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [10, 30, 50, 100, 150, 200, 500]\n",
    "# units = [500, 1000, 2000, 5000, 10000]\n",
    "# units = [100]\n",
    "\n",
    "hist_units_mse = []\n",
    "time_taken_units_mse = []\n",
    "test_loss_units_mse = []\n",
    "\n",
    "hist_units_mape = []\n",
    "time_taken_units_mape = []\n",
    "test_loss_units_mape = []\n",
    "\n",
    "for unit in units:\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(units=unit, return_sequences=False, input_shape=(INPUT_LENGTH, X_train.shape[-1])))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "    model.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist_units_mse.append(model.fit(X_train, y_train, epochs=1000, batch_size=360, callbacks=[earlystop, lr_scheduler], validation_split=0.2))\n",
    "    end_time = time.time()\n",
    "    time_taken_units_mse.append(end_time-start_time)\n",
    "\n",
    "    test_loss_units_mse.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "    model.save(model_path+'simplelstm-unit'+str(unit)+'.keras')\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # model = models.Sequential()\n",
    "    # model.add(layers.LSTM(units=unit, return_sequences=False, input_shape=(INPUT_LENGTH, X_train.shape[-1])))\n",
    "    # model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "    # model.compile(optimizer='adam', loss=losses.MeanAbsolutePercentageError())\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # hist_units_mape.append(model.fit(X_train, y_train, epochs=1000, batch_size=360, callbacks=[earlystop, lr_scheduler], validation_split=0.2))\n",
    "    # end_time = time.time()\n",
    "    # time_taken_units_mape.append(end_time-start_time)\n",
    "\n",
    "    # test_loss_units_mape.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "    # tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_epoch_mse = []\n",
    "for i, each in enumerate(hist_units_mse):\n",
    "    time_epoch_mse.append(time_taken_units_mse[i] / len(each.history['loss']))\n",
    "\n",
    "plt.plot(units, time_epoch_mse, marker='o')\n",
    "plt.xlabel('units')\n",
    "plt.ylabel('Average time taken of each epoch (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_units_mse = []\n",
    "for i, each in enumerate(hist_units_mse):\n",
    "    train_loss_units_mse.append(each.history['loss'][-1])\n",
    "\n",
    "plt.plot(test_loss_units_mse, label='Test Loss')\n",
    "plt.plot(train_loss_units_mse, label='Train Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "for i in range(len(hist_units_mse)):\n",
    "    axs[0].plot(hist_units_mse[i].history['loss'], \n",
    "                color=colors[i], \n",
    "                marker=markers[i], \n",
    "                label=f'{units[i]} Units')\n",
    "    axs[1].plot(hist_units_mse[i].history['val_loss'], \n",
    "                color=colors[i], \n",
    "                marker=markers[i], \n",
    "                label=f'{units[i]} Units')\n",
    "\n",
    "axs[0].set_ylabel('train loss (MSE)')\n",
    "axs[1].set_ylabel('validation loss (MSE)')\n",
    "axs[0].set_xlabel('epochs')\n",
    "axs[1].set_xlabel('epochs')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xscale('log')\n",
    "axs[0].set_ylim(0.5, 7)\n",
    "axs[1].set_ylim(0.5, 7)\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "for i in range(len(hist_units_mse)):\n",
    "    ax1.plot(hist_units_mse[i].history['loss'], \n",
    "            linestyle=line_styles[0], \n",
    "            color=colors[i], \n",
    "            marker=markers[i], \n",
    "            label=f'{units[i]} Units Train')\n",
    "    ax2.plot(hist_units_mse[i].history['val_loss'], \n",
    "            linestyle=line_styles[1], \n",
    "            color=colors[i], \n",
    "            marker=markers[i], \n",
    "            label=f'{units[i]} Units Validation')\n",
    "\n",
    "ax1.set_ylabel('train loss (MSE)')\n",
    "ax2.set_ylabel('validation loss (MSE)')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_yscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax1.set_ylim(6, 15)\n",
    "#ax2.set_ylim(10.5, 14)\n",
    "ax1.set_xscale('log')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "for i in range(len(hist_units_mape)):\n",
    "    ax1.plot(hist_units_mape[i].history['loss'], \n",
    "            linestyle=line_styles[0], \n",
    "            color=colors[i], \n",
    "            marker=markers[i], \n",
    "            label=f'{units[i]} Units Train')\n",
    "    # ax2.plot(hist_units_mape[i].history['val_loss'], \n",
    "    #         linestyle=line_styles[1], \n",
    "    #         color=colors[i], \n",
    "    #         marker=markers[i], \n",
    "    #         label=f'{units[i]} Units Validation')\n",
    "\n",
    "ax1.set_ylabel('train loss (MAPE)')\n",
    "# ax2.set_ylabel('validation loss (MAPE)')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_yscale('log')\n",
    "# ax2.set_yscale('log')\n",
    "# ax1.set_ylim(6, 15)\n",
    "#ax2.set_ylim(10.5, 14)\n",
    "ax1.set_xscale('log')\n",
    "ax1.legend(loc='upper right')\n",
    "# ax2.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if lr < 0.00005: return lr\n",
    "    if epoch < 5: return lr\n",
    "    else: return lr * 0.9\n",
    "lr_scheduler = callbacks.LearningRateScheduler(scheduler)\n",
    "earlystop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropouts = [0.1, 0.2, 0.5, 0.8]\n",
    "# dropouts = [0.5]\n",
    "\n",
    "hist_drop_mse = []\n",
    "test_loss_drop_mse = []\n",
    "\n",
    "hist_drop_mape = []\n",
    "test_loss_drop_mape = []\n",
    "for dropout in dropouts:\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(units=150, return_sequences=False, input_shape=(INPUT_LENGTH, X_train.shape[-1])))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "    model.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "    hist_drop_mse.append(model.fit(X_train, y_train, epochs=100, batch_size=360, callbacks=lr_scheduler, validation_split=0.2))\n",
    "    # hist_drop_mse[2] = model.fit(X_train, y_train, epochs=100, batch_size=360, callbacks=lr_scheduler, validation_split=0.2)\n",
    "\n",
    "    test_loss_drop_mse.append(model.evaluate(X_test, y_test))\n",
    "    # test_loss_drop_mse[2] = model.evaluate(X_test, y_test)\n",
    "\n",
    "    model.save(model_path+'simplelstm-dropout'+str(dropout)+'.keras')\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # model = models.Sequential()\n",
    "    # model.add(layers.LSTM(units=100, return_sequences=False, input_shape=(INPUT_LENGTH, X_train.shape[-1])))\n",
    "    # model.add(layers.Dropout(dropout))\n",
    "    # model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "    # model.compile(optimizer='adam', loss=losses.MeanAbsolutePercentageError())\n",
    "\n",
    "    # hist_drop_mape.append(model.fit(X_train, y_train, epochs=1000, batch_size=360, callbacks=earlystop, validation_split=0.2))\n",
    "    \n",
    "    # test_loss_drop_mape.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "    # tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "for i in range(len(hist_drop_mse)):\n",
    "    axs[0].plot(hist_drop_mse[i].history['loss'], \n",
    "                color=colors[i], \n",
    "                marker=markers[i], \n",
    "                label=f'{dropouts[i]} Dropout')\n",
    "    axs[1].plot(hist_drop_mse[i].history['val_loss'], \n",
    "                color=colors[i], \n",
    "                marker=markers[i], \n",
    "                label=f'{dropouts[i]} Dropout')\n",
    "\n",
    "axs[0].set_ylabel('train loss (MSE)')\n",
    "axs[1].set_ylabel('validation loss (MSE)')\n",
    "axs[0].set_xlabel('epochs')\n",
    "axs[1].set_xlabel('epochs')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xscale('log')\n",
    "axs[0].set_ylim(0.5, 4)\n",
    "axs[1].set_ylim(0.5, 4)\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sizes = [10, 30, 120, 360, 720, 1440]\n",
    "b_sizes = [120]\n",
    "\n",
    "hist_batch_mse = []\n",
    "time_taken_batch_mse = []\n",
    "test_loss_batch_mse = []\n",
    "\n",
    "hist_batch_mape = []\n",
    "time_taken_batch_mape = []\n",
    "test_loss_batch_mape = []\n",
    "\n",
    "for b_size in b_sizes:\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(units=150, return_sequences=False, input_shape=(INPUT_LENGTH, X_train.shape[-1])))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "    model.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist_batch_mse.append(model.fit(X_train, y_train, epochs=1000, batch_size=b_size, callbacks=[earlystop, lr_scheduler], validation_split=0.2))\n",
    "    end_time = time.time()\n",
    "    time_taken_batch_mse.append(end_time-start_time)\n",
    "\n",
    "    test_loss_batch_mse.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # model = models.Sequential()\n",
    "    # model.add(layers.LSTM(units=100, return_sequences=False, input_shape=(INPUT_LENGTH, FEATURE_COUNT+1)))\n",
    "    # model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "    # model.compile(optimizer='adam', loss=losses.MeanAbsolutePercentageError())\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # hist_batch_mape.append(model.fit(X_train, y_train, epochs=1000, batch_size=b_size, callbacks=[earlystop, lr_scheduler], validation_split=0.2))\n",
    "    # end_time = time.time()\n",
    "    # time_taken_batch_mape.append(end_time-start_time)\n",
    "\n",
    "    # test_loss_batch_mape.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "    # tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./trainloss.npy\", hist_batch_mse[0].history['loss'])\n",
    "np.save(\"./valloss.npy\", hist_batch_mse[0].history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_epoch_batch_mse = []\n",
    "for i, each in enumerate(hist_batch_mse):\n",
    "    time_epoch_batch_mse.append(time_taken_batch_mse[i] / len(each.history['loss']))\n",
    "\n",
    "plt.plot(b_sizes, time_taken_batch_mse, marker='o')\n",
    "plt.xlabel('batch_size')\n",
    "plt.ylabel('Average time taken of each epoch (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "for i in range(len(hist_batch_mse)):\n",
    "    axs[0].plot(hist_batch_mse[i].history['loss'], \n",
    "                color=colors[i], \n",
    "                marker=markers[i], \n",
    "                label=f'B = {b_sizes[i]}')\n",
    "    axs[1].plot(hist_batch_mse[i].history['val_loss'], \n",
    "                color=colors[i], \n",
    "                marker=markers[i], \n",
    "                label=f'B = {b_sizes[i]}')\n",
    "\n",
    "axs[0].set_ylabel('train loss (MSE)')\n",
    "axs[1].set_ylabel('validation loss (MSE)')\n",
    "axs[0].set_xlabel('epochs')\n",
    "axs[1].set_xlabel('epochs')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xscale('log')\n",
    "axs[0].set_ylim(0.5, 4)\n",
    "axs[1].set_ylim(0.5, 4)\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "for i in range(len(hist_batch_mse)):\n",
    "    ax1.plot(hist_batch_mse[i].history['loss'], \n",
    "            linestyle=line_styles[0], \n",
    "            color=colors[i], \n",
    "            marker=markers[i], \n",
    "            label=f'B = {b_sizes[i]} Train')\n",
    "    ax2.plot(hist_batch_mse[i].history['val_loss'], \n",
    "            linestyle=line_styles[1], \n",
    "            color=colors[i], \n",
    "            marker=markers[i], \n",
    "            label=f'B = {b_sizes[i]} Validation')\n",
    "\n",
    "ax1.set_ylabel('train loss (MSE)')\n",
    "ax2.set_ylabel('validation loss (MSE)')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_yscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax1.set_ylim(6.75, 10)\n",
    "#ax2.set_ylim(5.25, 6.5)\n",
    "ax1.set_xscale('log')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_speed1 = np.zeros((sortedData1.shape[0], sortedData1.shape[1], 4))\n",
    "for i, link in enumerate(upstreams):\n",
    "    for j, l in enumerate(link):\n",
    "        if l == -1: continue\n",
    "        else:\n",
    "            upstream_speed1[1:, i, j] = sortedData1[:-1, l, -1]\n",
    "upstream_speed2 = np.zeros((sortedData2.shape[0], sortedData2.shape[1], 4))\n",
    "for i, link in enumerate(upstreams):\n",
    "    for j, l in enumerate(link):\n",
    "        if l == -1: continue\n",
    "        else:\n",
    "            upstream_speed2[1:, i, j] = sortedData2[:-1, l, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data1 = tf.concat([upstream_speed1, temp_data1], 2)\n",
    "temp_data2 = tf.concat([upstream_speed2, temp_data2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_train = np.load(\"./trainloss.npy\")\n",
    "control_val = np.load(\"./valloss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 69\n",
    "train1, test1 = createSeq(temp_data1[:, id, :], INPUT_LENGTH, PREDICT_LENGTH, TEST_LEN)\n",
    "train2, test2 = createSeq(temp_data2[:, id, :], INPUT_LENGTH, PREDICT_LENGTH, TEST_LEN)\n",
    "\n",
    "X_train = tf.concat([train1[0], train2[0]], 0)\n",
    "y_train = tf.concat([train1[1], train2[1]], 0)\n",
    "X_test = tf.concat([test1[0], test2[0]], 0)\n",
    "y_test = tf.concat([test1[1], test2[1]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../datasets/local_x_train.npy', X_train)\n",
    "np.save('../datasets/local_y_train.npy', y_train)\n",
    "np.save('../datasets/local_x_test.npy', X_test)\n",
    "np.save('../datasets/local_y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, X_test = normalize(X_train, test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.LSTM(units=150, return_sequences=False, input_shape=(INPUT_LENGTH, X_train.shape[-1])))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "model.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_spat_mse = model.fit(X_train, y_train, epochs=200, batch_size=120, callbacks=[earlystop, lr_scheduler], validation_split=0.2)\n",
    "test_loss_spat_mse = model.evaluate(X_test, y_test)\n",
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path+'localized.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(model_path+'localized.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "earlystop = callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "model.add(layers.LSTM(units=200, return_sequences=False, input_shape=(INPUT_LENGTH, X_train.shape[-1])))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "model.compile(optimizer='adam', loss=losses.MeanAbsolutePercentageError())\n",
    "hist_spat_mape = model.fit(X_train, y_train, epochs=1000, batch_size=120, callbacks=[earlystop, lr_scheduler], validation_split=0.2)\n",
    "test_loss_spat_mape = model.evaluate(X_test, y_test)\n",
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_spat_mse.history['loss'], \n",
    "        linestyle=line_styles[0], \n",
    "        color=colors[0], \n",
    "        marker=markers[2], \n",
    "        label=\"Train loss with Spatial Featrues\")\n",
    "plt.plot(hist_spat_mse.history['val_loss'], \n",
    "        linestyle=line_styles[1], \n",
    "        color=colors[0], \n",
    "        marker=markers[2], \n",
    "        label=\"Validation loss with Spatial Featrues\")\n",
    "plt.plot(control_train, \n",
    "        linestyle=line_styles[0], \n",
    "        color=colors[1], \n",
    "        marker=markers[1], \n",
    "        label=\"Train loss of control group\")\n",
    "plt.plot(control_val, \n",
    "        linestyle=line_styles[1], \n",
    "        color=colors[1], \n",
    "        marker=markers[1], \n",
    "        label=\"Validation loss of control group\")\n",
    "plt.ylabel('loss (MSE)')\n",
    "plt.xlabel('epochs')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(hist_spat_mse.history['loss'], \n",
    "        linestyle=line_styles[0], \n",
    "        color=colors[0], \n",
    "        marker=markers[2], \n",
    "        label=\"Train loss with Spatial Featrues\")\n",
    "ax2.plot(hist_spat_mse.history['val_loss'], \n",
    "        linestyle=line_styles[1], \n",
    "        color=colors[0], \n",
    "        marker=markers[2], \n",
    "        label=\"Validation loss with Spatial Featrues\")\n",
    "ax1.plot(hist_batch_mse[2].history['loss'], \n",
    "        linestyle=line_styles[0], \n",
    "        color=colors[1], \n",
    "        marker=markers[1], \n",
    "        label=\"Train loss of control group\")\n",
    "ax2.plot(hist_batch_mse[2].history['val_loss'], \n",
    "        linestyle=line_styles[1], \n",
    "        color=colors[1], \n",
    "        marker=markers[1], \n",
    "        label=\"Validation loss of control group\")\n",
    "\n",
    "ax1.set_ylabel('train loss (MSE)')\n",
    "ax2.set_ylabel('validation loss (MSE)')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_yscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax1.set_ylim(5, 9)\n",
    "ax2.set_ylim(4, 15)\n",
    "ax1.set_xscale('log')\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_spat_mse.history['loss'][-1] / hist_units_mse[4].history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = random.sample([i for i in range(0, NUM_LINKS)], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_spat_ids = []\n",
    "test_loss_spat_ids = []\n",
    "\n",
    "missing_test = []\n",
    "missing_train = []\n",
    "\n",
    "for id in ids:\n",
    "    train1, test1 = createSeq(temp_data1[:, id, :], INPUT_LENGTH, PREDICT_LENGTH, TEST_LEN)\n",
    "    train2, test2 = createSeq(temp_data2[:, id, :], INPUT_LENGTH, PREDICT_LENGTH, TEST_LEN)\n",
    "\n",
    "    X_train = tf.concat([train1[0], train2[0]], 0)\n",
    "    y_train = tf.concat([train1[1], train2[1]], 0)\n",
    "    X_test = tf.concat([test1[0], test2[0]], 0)\n",
    "    y_test = tf.concat([test1[1], test2[1]], 0)\n",
    "    \n",
    "    missing_test.append(tf.reduce_sum(tf.cast(tf.equal(y_test, 0), dtype=tf.int32)).numpy() / (y_test.shape[0] * y_test.shape[1]))\n",
    "    missing_train.append(tf.reduce_sum(tf.cast(tf.equal(y_train, 0), dtype=tf.int32)).numpy() / (y_train.shape[0] * y_train.shape[1]))\n",
    "\n",
    "    X_train, _, X_test= normalize(X_train, test=X_test)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(units=200, return_sequences=False, input_shape=(INPUT_LENGTH, X_train.shape[-1])))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(units=PREDICT_LENGTH, activation='elu'))\n",
    "    model.compile(optimizer='adam', loss=losses.MeanAbsolutePercentageError())\n",
    "    \n",
    "    hist_spat_ids.append(model.fit(X_train, y_train, epochs=1000, batch_size=120, callbacks=[earlystop, lr_scheduler], validation_split=0.2))\n",
    "    test_loss_spat_ids.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = []\n",
    "vl = []\n",
    "for each in hist_spat_ids:\n",
    "    tl.append(each.history['loss'][-1])\n",
    "    vl.append(each.history['val_loss'][-1])\n",
    "\n",
    "x = np.arange(len(ids))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "is_h = ax.bar(x, tl, width, label=\"train\")\n",
    "# not_h = ax.bar(x + width/2, vl, width, label=\"validation\")\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "ax.set_ylabel(\"Final Loss (MAPE)\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(ids)\n",
    "ax.set_xlabel('Link ID')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl, tl, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globalised Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = tf.concat([sortedData1[:-VALIDATION_LEN-TEST_LEN], sortedData2[:-VALIDATION_LEN-TEST_LEN]], 0)\n",
    "temp_valid = tf.concat([sortedData1[-VALIDATION_LEN-TEST_LEN:-TEST_LEN], sortedData2[-VALIDATION_LEN-TEST_LEN:-TEST_LEN]], 0)\n",
    "temp_test = tf.concat([sortedData1[-TEST_LEN:], sortedData2[-TEST_LEN:]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../datasets/global_temp_train.npy', temp_train)\n",
    "np.save('../datasets/global_temp_val.npy', temp_valid)\n",
    "np.save('../datasets/global_temp_test.npy', temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = np.load('../datasets/global_temp_train.npy')\n",
    "temp_valid = np.load('../datasets/global_temp_val.npy')\n",
    "temp_test = np.load('../datasets/global_temp_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train, temp_valid, temp_test = normalize(temp_train, temp_valid, temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adj_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spac_data \u001b[38;5;241m=\u001b[39m \u001b[43madj_matrix\u001b[49m\n\u001b[1;32m      2\u001b[0m stat_data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(links[:, \u001b[38;5;241m2\u001b[39m], (links\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adj_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "spac_data = adj_matrix\n",
    "stat_data = tf.reshape(links[:, 2], (links.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createSTLSTM(\n",
    "    (INPUT_LENGTH, NUM_LINKS, FEATURE_COUNT), \n",
    "    (NUM_LINKS, NUM_LINKS), \n",
    "    (NUM_LINKS, SPAT_FEATURE_COUNT), \n",
    "    (PREDICT_LENGTH, NUM_LINKS)\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sizes = [120, 360, 720, 1440, 5040]\n",
    "\n",
    "hist_stlstm_mse = []\n",
    "time_taken_stlstm_mse = []\n",
    "test_loss_stlstm_mse = []\n",
    "\n",
    "hist_stlstm_mape = []\n",
    "time_taken_stlstm_mape = []\n",
    "test_loss_stlstm_mape = []\n",
    "\n",
    "for b_size in b_sizes:\n",
    "    train_generator = generateSTLSTMSeq(temp_train, INPUT_LENGTH, PREDICT_LENGTH, spac_data, stat_data, b_size)\n",
    "    validation_generator = generateSTLSTMSeq(temp_valid, INPUT_LENGTH, PREDICT_LENGTH, spac_data, stat_data, b_size)\n",
    "    test_generator = generateSTLSTMSeq(temp_test, INPUT_LENGTH, PREDICT_LENGTH, spac_data, stat_data, b_size)\n",
    "\n",
    "    model = createSTLSTM(\n",
    "        (INPUT_LENGTH, NUM_LINKS, FEATURE_COUNT), \n",
    "        (NUM_LINKS, NUM_LINKS), \n",
    "        (NUM_LINKS, SPAT_FEATURE_COUNT), \n",
    "        (PREDICT_LENGTH, NUM_LINKS)\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    hist_stlstm_mse.append(model.fit(\n",
    "        train_generator, \n",
    "        steps_per_epoch=temp_train.shape[0] // b_size, \n",
    "        epochs=100, \n",
    "        callbacks=earlystop, \n",
    "        validation_data=next(validation_generator)))\n",
    "    end_time = time.time()\n",
    "    time_taken_stlstm_mse.append(end_time-start_time)\n",
    "\n",
    "    test_loss_stlstm_mse.append(model.evaluate(test_generator, steps=temp_test.shape[0] // b_size))\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = createSTLSTM(\n",
    "        (INPUT_LENGTH, NUM_LINKS, FEATURE_COUNT), \n",
    "        (NUM_LINKS, NUM_LINKS), \n",
    "        (NUM_LINKS, SPAT_FEATURE_COUNT), \n",
    "        (PREDICT_LENGTH, NUM_LINKS), \n",
    "        losses.MeanAbsolutePercentageError()\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    hist_stlstm_mape.append(model.fit(\n",
    "        train_generator, \n",
    "        steps_per_epoch=temp_train.shape[0] // b_size, \n",
    "        epochs=100, \n",
    "        callbacks=earlystop, \n",
    "        validation_data=next(validation_generator)))\n",
    "    end_time = time.time()\n",
    "    time_taken_stlstm_mape.append(end_time-start_time)\n",
    "    \n",
    "    test_loss_stlstm_mape.append(model.evaluate(test_generator, steps=temp_test.shape[0] // b_size))\n",
    "    \n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train = np.empty(len(hist_stlstm_mse))\n",
    "MSE_valid = np.empty(len(hist_stlstm_mse))\n",
    "for i, each in enumerate(hist_stlstm_mse):\n",
    "    MSE_train[i] = each.history['loss'][-1]\n",
    "    MSE_valid[i] = each.history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train, MSE_valid, test_loss_stlstm_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE_train = np.empty(len(hist_stlstm_mape))\n",
    "MAPE_valid = np.empty(len(hist_stlstm_mape))\n",
    "for i, each in enumerate(hist_stlstm_mape):\n",
    "    MAPE_train[i] = each.history['loss'][-1]\n",
    "    MAPE_valid[i] = each.history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE_train, MAPE_valid, test_loss_stlstm_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_data = preprocessGraph(adj_matrix.numpy())\n",
    "stat_data = links[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../datasets/gcnlstm_spat.npy', spat_data)\n",
    "np.save('../datasets/gcnlstm_stat.npy', stat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_data = np.load('../datasets/gcnlstm_spat.npy')\n",
    "stat_data = tf.convert_to_tensor(np.load('../datasets/gcnlstm_stat.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_LSTM(keras.Model):\n",
    "    def __init__(\n",
    "            self, \n",
    "            temporal_input_shape, \n",
    "            adj_norm, \n",
    "            static_input_shape, \n",
    "            output_shape, \n",
    "            ):\n",
    "        super(GCN_LSTM, self).__init__()\n",
    "\n",
    "        gcn_units = FEATURE_COUNT\n",
    "        self.gcn = GCN(units=gcn_units, adj_norm=adj_norm)\n",
    "\n",
    "        self.flatten_stat = layers.Flatten()\n",
    "        self.repeat_stat = layers.RepeatVector(temporal_input_shape[0])\n",
    "        self.reshape_stat = layers.Reshape(\n",
    "            target_shape=(temporal_input_shape[0], static_input_shape[0], static_input_shape[1]), \n",
    "            name=\"Reshape_Static\"\n",
    "        )\n",
    "\n",
    "        self.concatenate = layers.Concatenate(axis=-1, name=\"Concatenate\")\n",
    "\n",
    "        # self.conv2d = layers.Conv2D(\n",
    "        #     filters=1, \n",
    "        #     kernel_size=(1, 1), \n",
    "        #     activation='relu',\n",
    "        #     name=\"Conv2D\"\n",
    "        # )\n",
    "        # self.reshape_all = layers.Reshape(\n",
    "        #     target_shape=(temporal_input_shape[0], static_input_shape[0]),\n",
    "        #     name=\"Reshape_All\"\n",
    "        # )\n",
    "\n",
    "        # self.lstm = keras.Sequential([\n",
    "        #     layers.GRU(units=200, dropout=0.2, return_sequences=True, activation='elu'),\n",
    "        #     layers.GRU(units=200, dropout=0.2, activation='elu')\n",
    "        #     ], name=\"LSTM_Layers\"\n",
    "        # )\n",
    "\n",
    "        self.lstm = [\n",
    "            keras.Sequential([\n",
    "                layers.LSTM(units=50, dropout=0.2),\n",
    "                layers.Dense(units=output_shape[0], activation='elu')\n",
    "            ]) for _ in range(static_input_shape[0])]\n",
    "\n",
    "        # self.dense = keras.Sequential([\n",
    "        #     layers.Dense(units=1000, activation='elu'),\n",
    "        #     layers.Dense(units=output_shape[0]*output_shape[1], activation='elu')\n",
    "        #     ], name=\"Dense_Layers\"\n",
    "        # )\n",
    "\n",
    "        # self.reshape_out = layers.Reshape(\n",
    "        #     target_shape=(output_shape[0], output_shape[1]),\n",
    "        #     name=\"Reshape_Output\"\n",
    "        # )\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        temp = inputs[0]    # [30, 132, 19]\n",
    "        stat = inputs[1]    # [132, 1]\n",
    "        \n",
    "        # [132, 1] -> [30, 132, 1]\n",
    "        stat = self.flatten_stat(stat)\n",
    "        stat = self.repeat_stat(stat)\n",
    "        stat = self.reshape_stat(stat)\n",
    "\n",
    "        # [30, 132, 19] -> [30, 132, 19]\n",
    "        # temp = self.gcn(temp)\n",
    "\n",
    "        # [30, 132, 19] + [30, 132, 1]\n",
    "        al = self.concatenate([temp, stat])\n",
    "\n",
    "        # [30, 132, 20] -> [30, 132, 1] -> [30, 132]\n",
    "        # al = self.conv2d(al)\n",
    "        # al = self.reshape_all(al)\n",
    "\n",
    "        # [30, 132] -> [100]\n",
    "        # al = self.lstm(al)\n",
    "        gru_outputs = []\n",
    "        for i in range(132):\n",
    "            link = al[:, :, i, :]\n",
    "            gru_output = self.lstm[i](link)\n",
    "            gru_outputs.append(gru_output)\n",
    "\n",
    "        # al = tf.transpose(tf.convert_to_tensor(gru_outputs), perm=[1, 2, 0])\n",
    "        al = tf.stack(gru_outputs, axis=2)\n",
    "        # print(al.shape)\n",
    "\n",
    "        # [100] -> [15*132] -> [15, 132]\n",
    "        # al = self.dense(al)\n",
    "        # al = self.reshape_out(al)\n",
    "\n",
    "        return al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGCN_LSTM(temporal_shape, adj_norm, static_shape, output_shape, loss=losses.MeanSquaredError()):\n",
    "    model = GCN_LSTM(\n",
    "        temporal_input_shape=temporal_shape,\n",
    "        adj_norm=adj_norm,\n",
    "        static_input_shape=static_shape,\n",
    "        output_shape=output_shape\n",
    "    )\n",
    "\n",
    "    model.build(input_shape=[(None, )+temporal_shape, (None, )+static_shape])\n",
    "    model.compile(optimizer='adam', loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gcn_lstm_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gcn_2 (GCN)                 multiple                  0 (unused)\n",
      "                                                                 \n",
      " flatten_2 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVec  multiple                  0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " Reshape_Static (Reshape)    multiple                  0         \n",
      "                                                                 \n",
      " Concatenate (Concatenate)   multiple                  0         \n",
      "                                                                 \n",
      " sequential_264 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_265 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_266 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_267 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_268 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_269 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_270 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_271 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_272 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_273 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_274 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_275 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_276 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_277 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_278 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_279 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_280 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_281 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_282 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_283 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_284 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_285 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_286 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_287 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_288 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_289 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_290 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_291 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_292 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_293 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_294 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_295 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_296 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_297 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_298 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_299 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_300 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_301 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_302 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_303 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_304 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_305 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_306 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_307 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_308 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_309 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_310 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_311 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_312 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_313 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_314 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_315 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_316 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_317 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_318 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_319 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_320 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_321 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_322 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_323 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_324 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_325 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_326 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_327 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_328 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_329 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_330 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_331 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_332 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_333 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_334 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_335 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_336 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_337 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_338 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_339 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_340 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_341 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_342 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_343 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_344 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_345 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_346 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_347 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_348 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_349 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_350 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_351 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_352 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_353 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_354 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_355 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_356 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_357 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_358 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_359 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_360 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_361 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_362 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_363 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_364 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_365 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_366 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_367 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_368 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_369 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_370 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_371 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_372 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_373 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_374 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_375 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_376 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_377 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_378 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_379 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_380 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_381 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_382 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_383 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_384 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_385 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_386 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_387 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_388 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_389 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_390 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_391 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_392 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_393 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_394 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_395 (Sequential  (None, 15)                15165     \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2001780 (7.64 MB)\n",
      "Trainable params: 2001780 (7.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createGCN_LSTM(\n",
    "    (INPUT_LENGTH, NUM_LINKS, FEATURE_COUNT), \n",
    "    spat_data, \n",
    "    (NUM_LINKS, SPAT_FEATURE_COUNT), \n",
    "    (PREDICT_LENGTH, NUM_LINKS))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generateGCN_LSTMSeq(temp_train, INPUT_LENGTH, PREDICT_LENGTH, stat_data, BATCH_SIZE)\n",
    "validation_generator = generateGCN_LSTMSeq(temp_valid, INPUT_LENGTH, PREDICT_LENGTH, stat_data, BATCH_SIZE)\n",
    "test_generator = generateGCN_LSTMSeq(temp_test, INPUT_LENGTH, PREDICT_LENGTH, stat_data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "924/924 [==============================] - 186s 108ms/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 2/10\n",
      "924/924 [==============================] - 87s 95ms/step - loss: 1.4234e-04 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "924/924 [==============================] - 87s 94ms/step - loss: 1.1672e-04 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "924/924 [==============================] - 85s 92ms/step - loss: 1.0612e-04 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "924/924 [==============================] - 86s 93ms/step - loss: 9.8800e-05 - val_loss: 8.1981e-04\n",
      "Epoch 6/10\n",
      "924/924 [==============================] - 85s 92ms/step - loss: 9.2564e-05 - val_loss: 6.1327e-04\n",
      "Epoch 7/10\n",
      "924/924 [==============================] - 85s 92ms/step - loss: 8.6959e-05 - val_loss: 4.8486e-04\n",
      "Epoch 8/10\n",
      "924/924 [==============================] - 85s 92ms/step - loss: 8.2767e-05 - val_loss: 4.1682e-04\n",
      "Epoch 9/10\n",
      "924/924 [==============================] - 85s 92ms/step - loss: 7.9659e-05 - val_loss: 3.7467e-04\n",
      "Epoch 10/10\n",
      "924/924 [==============================] - 85s 92ms/step - loss: 7.7457e-05 - val_loss: 3.5674e-04\n"
     ]
    }
   ],
   "source": [
    "earlystop = callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=3, verbose=1, restore_best_weights=True)\n",
    "lr_scheduler = callbacks.LearningRateScheduler(scheduler)\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=temp_train.shape[0] // BATCH_SIZE, \n",
    "    epochs=10, \n",
    "    callbacks=earlystop, \n",
    "    validation_data=next(validation_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_path+'global_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
