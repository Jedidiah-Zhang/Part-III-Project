%% ----------------------------------------------------------------
%% UOS.bib
%% ---------------------------------------------------------------- 
@MISC{Dataset, 
    title =   {Traffic Prediction Dataset},
    url =     {https://tianchi.aliyun.com/dataset/dataDetail?dataId=1079},
    author =  {Tianchi},
    year =    {2018}
}

@book{Bishop,
    author         = {Christopher M. Bishop},
    publisher      = {springer},
    title          = {Pattern Recognition and Machine Learning},
    year           = {2006}
}

@book{Murphy,
    title           = {Machine Learning: A Probabilistic Perspective},
    author          = {Murphy, Kevin P},
    year            = {2012},
    publisher       = {MIT press Cambridge}
}

@book{Hyndman,
    title           = {Forecasting: principles and practice, 2nd edition},
    author          = {Hyndman, R.J.},
    year            = {2012},
    publisher       = {OTexts: Melbourne, Australia}
}

@article{Koc,
    author = {Kocadağlı, Ozan and Aşıkgil, Barış},
    year = {2014},
    month = {11},
    pages = {6596–6610},
    title = {Nonlinear time series forecasting with Bayesian neural networks},
    volume = {41},
    journal = {Expert Systems with Applications},
    doi = {10.1016/j.eswa.2014.04.035}
}

@MISC{activation, 
    title =   {Hands-on Machine Learning with Scikit-Learn, Keras and Tensorflow},
    url =     {https://www.vlebooks.com/Product/Index/1609613},
    author =  {A. Geron},
    year =    {2019}
}

@MISC{rnnplot, 
    title =   {Visualizations of RNN units Diagrams of RNN unrolling, LSTM and GRU.},
    url =     {https://kvitajakub.github.io/2016/04/14/rnn-diagrams/},
    author =  {Jakub Kvita},
    year =    {2016}
}

@misc{ribeiro2020exploding,
    title={Beyond exploding and vanishing gradients: analysing RNN training using attractors and smoothness}, 
    author={Antônio H. Ribeiro and Koen Tiels and Luis A. Aguirre and Thomas B. Schön},
    year={2020},
    eprint={1906.08482},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{lstm,
    author = {Hochreiter Sepp and Schmidhuber Jürgen},
    year = {1997},
    month = {12},
    pages = {1735-80},
    title = {Long Short-term Memory},
    volume = {9},
    journal = {Neural computation},
    doi = {10.1162/neco.1997.9.8.1735}
}

@article{TIAN2018297,
    title = {LSTM-based traffic flow prediction with missing data},
    journal = {Neurocomputing},
    volume = {318},
    pages = {297-305},
    year = {2018},
    issn = {0925-2312},
    doi = {https://doi.org/10.1016/j.neucom.2018.08.067},
    url = {https://www.sciencedirect.com/science/article/pii/S0925231218310294},
    author = {Yan Tian and Kaili Zhang and Jianyuan Li and Xianxuan Lin and Bailin Yang},
}

@INPROCEEDINGS{8560205,
    author={Zhene, Zou and Hao, Peng and Lin, Liu and Guixi, Xiong and Du, Bowen and Bhuiyan, Md Zakirul Alam and Long, Yuntao and Li, Da},
    booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, 
    title={Deep Convolutional Mesh RNN for Urban Traffic Passenger Flows Prediction}, 
    year={2018},
    volume={},
    number={},
    pages={1305-1310},
    doi={10.1109/SmartWorld.2018.00227}
}

@article{DBLP:journals/corr/abs-1709-04875,
    author       = {Bing Yu andHaoteng Yin and Zhanxing Zhu},
    title        = {Spatio-temporal Graph Convolutional Neural Network: {A} Deep Learning Framework for Traffic Forecasting},
    journal      = {CoRR},
    volume       = {abs/1709.04875},
    year         = {2017},
    url          = {http://arxiv.org/abs/1709.04875},
    eprinttype    = {arXiv},
    eprint       = {1709.04875},
    timestamp    = {Mon, 13 Aug 2018 16:47:55 +0200},
    biburl       = {https://dblp.org/rec/journals/corr/abs-1709-04875.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{lipton2015critical,
    title={A Critical Review of Recurrent Neural Networks for Sequence Learning}, 
    author={Zachary C. Lipton and John Berkowitz and Charles Elkan},
    year={2015},
    eprint={1506.00019},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Sieci,
    title = {Sieci Neuronowe},
    journal = {Akademicka Oficyna Wydawnicza RM},
    volume = {110},
    pages = {236},
    year = {1993},
    url = {https://www.academia.edu/30816962/Sieci_Neuronowe},
    author = {Ryszard Tadeusiewicz}
}

@article{Pinkus_1999, 
    title={Approximation theory of the MLP model in neural networks}, 
    volume={8}, 
    DOI={10.1017/S0962492900002919}, 
    journal={Acta Numerica}, 
    author={Pinkus, Allan}, 
    year={1999}, 
    pages={143-195}
}

@incollection{HECHTNIELSEN199265,
    title = {III.3 - Theory of the Backpropagation Neural Network**Based on “nonindent” by Robert Hecht-Nielsen, which appeared in Proceedings of the International Joint Conference on Neural Networks 1, 593–611, June 1989. © 1989 IEEE.},
    editor = {Harry Wechsler},
    booktitle = {Neural Networks for Perception},
    publisher = {Academic Press},
    pages = {65-93},
    year = {1992},
    isbn = {978-0-12-741252-8},
    doi = {https://doi.org/10.1016/B978-0-12-741252-8.50010-8},
    url = {https://www.sciencedirect.com/science/article/pii/B9780127412528500108},
    author = {ROBERT HECHT-NIELSEN}
}

@article{Poggio2016WhyAW,
    title={Why and when can deep-but not shallow-networks avoid the curse of dimensionality: A review},
    author={Tomaso A. Poggio and Hrushikesh Narhar Mhaskar and Lorenzo Rosasco and Brando Miranda and Qianli Liao},
    journal={International Journal of Automation and Computing},
    year={2016},
    volume={14},
    pages={503 - 519},
    url={https://api.semanticscholar.org/CorpusID:15562587}
}

@ARTICLE{726791,
    author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
    journal={Proceedings of the IEEE}, 
    title={Gradient-based learning applied to document recognition}, 
    year={1998},
    volume={86},
    number={11},
    pages={2278-2324},
    keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
    doi={10.1109/5.726791}
}

@MISC{poolingplot, 
    title =   {Convolutional Neural Networks Explained — How To Successfully Classify Images in Python},
    url =     {https://towardsdatascience.com/convolutional-neural-networks-explained-how-to-successfully-classify-images-in-python-df829d4ba761},
    author =  {Saul Dobilas},
    year =    {2022}
}

@article{Kipf2016SemiSupervisedCW,
    title={Semi-Supervised Classification with Graph Convolutional Networks},
    author={Thomas Kipf and Max Welling},
    journal={ArXiv},
    year={2016},
    volume={abs/1609.02907},
    url={https://api.semanticscholar.org/CorpusID:3144218}
}

@MISC{Thomas, 
    title =   {Graph Convolutional Networks},
    url =     {https://tkipf.github.io/graph-convolutional-networks/},
    author =  {Thomas Kipf},
    year =    {2016}
}

@article{PeMS,
    author = {Chao Chen and Karl Petty and Alexander Skabardonis and Pravin Varaiya and Zhanfeng Jia},
    title ={Freeway Performance Measurement System: Mining Loop Detector Data},
    journal = {Transportation Research Record},
    volume = {1748},
    number = {1},
    pages = {96-102},
    year = {2001},
    doi = {10.3141/1748-12},
    URL = {https://doi.org/10.3141/1748-12},
    eprint = {https://doi.org/10.3141/1748-12},
    abstract = { Performance Measurement System (PeMS) is a freeway performance measurement system for all of California. It processes 2 GB/day of 30-s loop detector data in real time to produce useful information. At any time managers can have a uniform, comprehensive assessment of freeway performance. Traffic engineers can base their operational decisions on knowledge of the current status of the freeway network. Planners can determine whether congestion bottlenecks can be alleviated by improving operations or by minor capital improvements. Travelers can obtain the current shortest route and travel time estimates. Researchers can validate their theory and calibrate simulation models. PeMS, which has been in stable operation for 18 months, is a low-cost system. It uses the California Department of Transportation (Caltrans) network for data acquisition and is easy to deploy and maintain. It takes under 6 weeks to bring a Caltrans district online, and functionality can be added incrementally. PeMS applications are accessed over the World Wide Web; custom applications can work directly with the PeMS database. Built as a prototype, PeMS can be transitioned into a 7 × 24 production system. The PeMS architecture and use are described. }
}

@inproceedings{Yu_2018, 
    series={IJCAI-2018},
    title={Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting},
    url={http://dx.doi.org/10.24963/ijcai.2018/505},
    DOI={10.24963/ijcai.2018/505},
    booktitle={Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence},
    publisher={International Joint Conferences on Artificial Intelligence Organization},
    author={Yu, Bing and Yin, Haoteng and Zhu, Zhanxing},
    year={2018},
    month=jul, 
    collection={IJCAI-2018}
}

@article{Santos_2022,
    title={Avoiding Overfitting: A Survey on Regularization Methods for Convolutional Neural Networks},
    volume={54},
    ISSN={1557-7341},
    url={http://dx.doi.org/10.1145/3510413},
    DOI={10.1145/3510413},
    number={10s},
    journal={ACM Computing Surveys},
    publisher={Association for Computing Machinery (ACM)},
    author={Santos, Claudio Filipi Gonçalves Dos and Papa, João Paulo},
    year={2022},
    month=jan, pages={1–25} 
    }